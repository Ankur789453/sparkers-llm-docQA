# ğŸ“„ HackRx 6.0 â€” LLM-powered Query-Retrieval System



A modern FastAPI backend that allows users to:

- Upload documents (PDF/DOCX)
- Ask complex domain-specific questions (e.g., Insurance/Legal)
- Get accurate answers powered by **semantic search**, **FAISS**, and **LLMs** like GPT & Mixtral

---

## ğŸš€ Features

âœ… Upload & parse documents (PDF/DOCX)\
âœ… Semantic chunk-based retrieval via FAISS\
âœ… Clause-aware QA with rationale and sources\
âœ… Switch between OpenAI and Groq (Mixtral) backends\
âœ… Public `/hackrx/run` endpoint for HackRx integration

---

## ğŸ› ï¸ Project Structure

```
Hackrx_6.0-main/
â”‚
â”œâ”€â”€ .env                      # API keys and configuration
â”œâ”€â”€ payload.json              # Sample payload for testing
â”œâ”€â”€ requirements.txt          # Project dependencies
â”œâ”€â”€ test_request.py           # Script to test HackRx endpoint
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py               # FastAPI app with endpoints
â”‚   â”œâ”€â”€ app_config.py         # Environment variables (pydantic)
â”‚
â”‚   â”œâ”€â”€ parsers/
â”‚   â”‚   â””â”€â”€ file_parser.py    # Local DOCX/PDF parsing
â”‚
â”‚   â”œâ”€â”€ retrieval/
â”‚   â”‚   â”œâ”€â”€ search_engine.py  # Semantic search logic
â”‚   â”‚   â””â”€â”€ embedding_engine.py  # FAISS vector indexing
â”‚
â”‚   â”œâ”€â”€ llm_wrappers/
â”‚   â”‚   â”œâ”€â”€ qa_engine.py      # Uses Groq/OpenAI for answering
â”‚   â”‚   â””â”€â”€ llm_engine.py     # Model handler (extensible)
â”‚
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ schema.py         # Request/response models
â”‚
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ text_splitter.py      # Chunking logic
â”‚       â””â”€â”€ download_and_parse.py # Remote PDF downloader
```

---

## ğŸ”§ Setup & Installation

```bash
# 1. Create virtualenv (optional)
conda create -n hackrx python=3.10 -y
conda activate hackrx

# 2. Install dependencies
pip install -r requirements.txt

# 3. Add your API keys to `.env`
```

### .env Example:

```env
OPENAI_API_KEY=sk-...
GROQ_API_KEY=gsk-...
GROQ_MODEL_NAME=llama3-70b-8192
OPENAI_MODEL_NAME=gpt-3.5-turbo
TEMPERATURE=0.1
MAX_TOKENS=1024
CHUNK_SIZE=500
CHUNK_OVERLAP=50
API_AUTH_TOKEN=Bearer your_api_token_here
```

---

## âš™ï¸ Run the Backend

```bash
uvicorn app.main:app --reload
```

---

## ğŸ“¤ Upload Endpoint

```
POST /upload
```

> Uploads a document and indexes it using FAISS.

### Response:

```json
{
  "message": "âœ… File uploaded and indexed successfully",
  "file_id": "abc-123-uuid",
  "file_name": "policy.pdf",
  "chunk_count": 21
}
```

---

## â“ Ask Endpoint

```
POST /ask
```

> Ask a single question based on previously uploaded document.

**Form Data:**

- `question`: Your query
- `file_id`: ID returned during upload
- `provider`: `groq` or `openai` (default: `groq`)

---

## ğŸ”¥ HackRx Public API

```
POST /hackrx/run
```

> Directly hit the LLM-powered query system with a PDF URL + multiple questions.

### Payload:

```json
{
  "documents": "https://example.com/policy.pdf",
  "questions": [
    "What is the waiting period for cataract?",
    "Are maternity expenses covered?"
  ]
}
```

### Response:

```json
{
  "answers": [
    "24 months",
    "Yes, up to â‚¹25,000 with conditions"
  ]
}
```

---

## ğŸ“¦ Included Files

- `payload.json` â†’ For testing `/hackrx/run`
- `test_request.py` â†’ Script to simulate external HackRx call
- `README.md` â†’ You're reading it ğŸ“
- `Procfile` â†’ For deployment (Heroku compatible)

---

## ğŸ§  Powered By

- **FAISS** for vector similarity
- **SentenceTransformers** for embeddings
- **Groq (Mixtral)** & **OpenAI (GPT-3.5)** for answering
- **FastAPI** for blazing-fast backend

---

## ğŸ Future Upgrades

-

---

## ğŸ’™ Made for HackRx 6.0 by Ankur Jangra (Billu)

> "Query Smart, Retrieve Smarter."

---

## ğŸŒ License

MIT License. Use freely with attribution.

---

> Need help or want to contribute? Open a PR or raise an issue ğŸ™Œ

